{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T18:16:56.090006Z",
     "start_time": "2019-12-21T18:16:51.421519Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/eynatgrof/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n",
      "[nltk_data] Downloading package punkt to /Users/eynatgrof/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import glob\n",
    "import codecs\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import string\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics  import accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T19:16:41.656154Z",
     "start_time": "2019-12-21T19:16:41.646675Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/eynatgrof/Documents/projects/imdb/aclImdb\n"
     ]
    }
   ],
   "source": [
    "path = os.getcwd() + '/aclImdb'\n",
    "print(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T18:17:24.500323Z",
     "start_time": "2019-12-21T18:17:04.053467Z"
    }
   },
   "outputs": [],
   "source": [
    "path_train_neg = path + '/train/neg/*txt'\n",
    "path_train_pos = path + '/train/pos/*txt'\n",
    "path_test_neg = path + '/test/neg/*txt'\n",
    "path_test_pos = path +'/test/pos/*txt'\n",
    "train_neg = []\n",
    "train_pos = []\n",
    "test_neg = []\n",
    "test_pos = []\n",
    "\n",
    "paths = [path_train_neg, path_train_pos, path_test_neg, path_test_pos]\n",
    "lists = [train_neg, train_pos, test_neg, test_pos]\n",
    "\n",
    "for i in range(len(paths)):\n",
    "        path = paths[i]\n",
    "        lst = lists[i]\n",
    "        \n",
    "        files = glob.glob(path)\n",
    "        \n",
    "        for name in files:\n",
    "            try:\n",
    "                with open(name) as f:\n",
    "                    file = [line.split() for line in f]\n",
    "                    flat_file = [item for item in file for item in item]\n",
    "                    lst.append(flat_file)\n",
    "            except:\n",
    "                print('error with', name)\n",
    "                "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stemming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T18:17:28.241011Z",
     "start_time": "2019-12-21T18:17:28.233254Z"
    }
   },
   "outputs": [],
   "source": [
    "def stem_func(reviews_lst):\n",
    "    stemmer = PorterStemmer()\n",
    "    revised_lst = []\n",
    "    count = 0\n",
    "    for review in reviews_lst:\n",
    "        temp_lst = []\n",
    "        for word in range(len(review)):\n",
    "            temp_lst.append(stemmer.stem(review[word]))\n",
    "        revised_lst.append(temp_lst)\n",
    "        count += 1\n",
    "        print(count, end = '\\r')\n",
    "    print('done')\n",
    "    return revised_lst\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T18:21:55.167714Z",
     "start_time": "2019-12-21T18:17:31.883265Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done0\n",
      "done0\n",
      "done0\n",
      "done0\n"
     ]
    }
   ],
   "source": [
    "train_neg = stem_func(train_neg)\n",
    "train_pos = stem_func(train_pos)\n",
    "test_neg = stem_func(test_neg)\n",
    "test_pos = stem_func(test_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing stop words and punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T18:21:59.567732Z",
     "start_time": "2019-12-21T18:21:59.556829Z"
    }
   },
   "outputs": [],
   "source": [
    "def stop_func(reviews_lst):\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    stop_words.add('/><br')\n",
    "    \n",
    "    revised_lst = []\n",
    "    count = 0\n",
    "    for review in reviews_lst:\n",
    "        temp_lst = []\n",
    "        for word in range(len(review)):\n",
    "            if review[word] not in stop_words:\n",
    "                temp_lst.append(review[word])\n",
    "            for word in range(len(temp_lst)):\n",
    "                temp_lst[word] = temp_lst[word].translate(str.maketrans('','', string.punctuation))\n",
    "        count += 1\n",
    "        print(count, end = '\\r')\n",
    "        revised_lst.append(temp_lst)\n",
    "    print('done')\n",
    "    return revised_lst\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T19:13:17.738358Z",
     "start_time": "2019-12-21T18:22:04.445364Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done0\n",
      "done0\n",
      "done0\n",
      "done0\n"
     ]
    }
   ],
   "source": [
    "train_neg = stop_func(train_neg)\n",
    "train_pos = stop_func(train_pos)\n",
    "test_neg = stop_func(test_neg)\n",
    "test_pos = stop_func(test_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Replicate dictionary method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dictionary negative and positive words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T19:13:23.757358Z",
     "start_time": "2019-12-21T19:13:23.747744Z"
    }
   },
   "outputs": [],
   "source": [
    "def isNotNull(value):\n",
    "    return value is not None and len(value)>0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T19:16:46.432790Z",
     "start_time": "2019-12-21T19:16:46.415902Z"
    }
   },
   "outputs": [],
   "source": [
    "dict_pos = []\n",
    "dict_neg = []\n",
    "f = open('negative-words.txt','r', encoding = 'ISO-8859-1')\n",
    "for line in f:\n",
    "    t = line.strip().lower();\n",
    "    if (isNotNull(t)):\n",
    "        dict_neg.append(t)\n",
    "f.close()\n",
    "\n",
    "f = open('positive-words.txt','r', encoding = 'ISO-8859-1')\n",
    "for line in f:\n",
    "    t = line.strip().lower();\n",
    "    if (isNotNull(t)):\n",
    "        dict_pos.append(t)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T19:16:49.630975Z",
     "start_time": "2019-12-21T19:16:49.627515Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a+', 'abound', 'abounds', 'abundance', 'abundant']\n",
      "['2-faced', '2-faces', 'abnormal', 'abolish', 'abominable']\n"
     ]
    }
   ],
   "source": [
    "print(dict_pos[:5])\n",
    "print(dict_neg[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dictionary analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T19:16:53.104296Z",
     "start_time": "2019-12-21T19:16:52.775452Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[alan, rickman, , emma, thompson, give, good, ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[I, seen, thi, movi, I, care, thi, movi, anyho...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[In, lo, angeles, alcohol, lazi, hank, chinask...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[thi, film, bundl, along, gli, fumavano, le, c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[I, onli, comment, realli, veri, good, film, u...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label\n",
       "0  [alan, rickman, , emma, thompson, give, good, ...      0\n",
       "1  [I, seen, thi, movi, I, care, thi, movi, anyho...      0\n",
       "2  [In, lo, angeles, alcohol, lazi, hank, chinask...      0\n",
       "3  [thi, film, bundl, along, gli, fumavano, le, c...      0\n",
       "4  [I, onli, comment, realli, veri, good, film, u...      0"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1 = pd.DataFrame()\n",
    "df1['review'] = test_neg\n",
    "df2 = pd.DataFrame()\n",
    "df2['review'] = test_pos\n",
    "\n",
    "frames = [df1, df2]\n",
    "data = pd.concat(frames)\n",
    "data['label'] = [0]*len(test_neg) + [1]*len(test_pos)\n",
    "print(len(data))\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T19:23:22.229297Z",
     "start_time": "2019-12-21T19:16:56.247300Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000\r"
     ]
    }
   ],
   "source": [
    "analysis_for_all = []\n",
    "count = 0\n",
    "for i in range(len(data)):\n",
    "    tokens = data.iloc[i,0]\n",
    "    neg_cnt = 0\n",
    "    pos_cnt = 0\n",
    "    for neg in dict_neg:\n",
    "        if (neg in tokens):\n",
    "            neg_cnt = neg_cnt +1\n",
    "    for pos in dict_pos:\n",
    "        if (pos in tokens):\n",
    "            pos_cnt = pos_cnt +1\n",
    "    analysis_for_all.append(pos_cnt - neg_cnt)   \n",
    "    count += 1\n",
    "    print(count, end = '\\r')\n",
    "data['Bing_analysis_for_all'] = analysis_for_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T19:23:25.569342Z",
     "start_time": "2019-12-21T19:23:25.556239Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>Bing_analysis_for_all</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[alan, rickman, , emma, thompson, give, good, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[I, seen, thi, movi, I, care, thi, movi, anyho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[In, lo, angeles, alcohol, lazi, hank, chinask...</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[thi, film, bundl, along, gli, fumavano, le, c...</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[I, onli, comment, realli, veri, good, film, u...</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label  \\\n",
       "0  [alan, rickman, , emma, thompson, give, good, ...      0   \n",
       "1  [I, seen, thi, movi, I, care, thi, movi, anyho...      0   \n",
       "2  [In, lo, angeles, alcohol, lazi, hank, chinask...      0   \n",
       "3  [thi, film, bundl, along, gli, fumavano, le, c...      0   \n",
       "4  [I, onli, comment, realli, veri, good, film, u...      0   \n",
       "\n",
       "   Bing_analysis_for_all  \n",
       "0                      4  \n",
       "1                      1  \n",
       "2                     -2  \n",
       "3                     -9  \n",
       "4                     -3  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T19:23:32.677761Z",
     "start_time": "2019-12-21T19:23:32.650411Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>label</th>\n",
       "      <th>Bing_analysis_for_all</th>\n",
       "      <th>analysis_label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[alan, rickman, , emma, thompson, give, good, ...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[I, seen, thi, movi, I, care, thi, movi, anyho...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[In, lo, angeles, alcohol, lazi, hank, chinask...</td>\n",
       "      <td>0</td>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[thi, film, bundl, along, gli, fumavano, le, c...</td>\n",
       "      <td>0</td>\n",
       "      <td>-9</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[I, onli, comment, realli, veri, good, film, u...</td>\n",
       "      <td>0</td>\n",
       "      <td>-3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  label  \\\n",
       "0  [alan, rickman, , emma, thompson, give, good, ...      0   \n",
       "1  [I, seen, thi, movi, I, care, thi, movi, anyho...      0   \n",
       "2  [In, lo, angeles, alcohol, lazi, hank, chinask...      0   \n",
       "3  [thi, film, bundl, along, gli, fumavano, le, c...      0   \n",
       "4  [I, onli, comment, realli, veri, good, film, u...      0   \n",
       "\n",
       "   Bing_analysis_for_all  analysis_label  \n",
       "0                      4               1  \n",
       "1                      1               1  \n",
       "2                     -2               0  \n",
       "3                     -9               0  \n",
       "4                     -3               0  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "analysis_label = []\n",
    "for i in analysis_for_all:\n",
    "    if i >0:\n",
    "        analysis_label.append(1)\n",
    "    else:\n",
    "        analysis_label.append(0)\n",
    "\n",
    "data['analysis_label'] = analysis_label\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T19:23:38.342267Z",
     "start_time": "2019-12-21T19:23:38.281966Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[9280, 3220],\n",
       "       [4107, 8393]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Bing_analysis = data.analysis_label.tolist()\n",
    "True_label = data.label.tolist()\n",
    "confusion_matrix(True_label,Bing_analysis)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T19:23:41.608849Z",
     "start_time": "2019-12-21T19:23:41.544759Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.74      0.72     12500\n",
      "           1       0.72      0.67      0.70     12500\n",
      "\n",
      "    accuracy                           0.71     25000\n",
      "   macro avg       0.71      0.71      0.71     25000\n",
      "weighted avg       0.71      0.71      0.71     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(True_label,Bing_analysis))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose a different ML method\n",
    "## Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T19:23:45.082209Z",
     "start_time": "2019-12-21T19:23:44.778550Z"
    },
    "code_folding": [],
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_pos_nb = []\n",
    "for i in range(len(train_pos)):\n",
    "    temp = \" \".join(train_pos[i])\n",
    "    train_pos_nb.append(temp)\n",
    "    \n",
    "train_neg_nb = []\n",
    "for i in range(len(train_neg)):\n",
    "    temp = \" \".join(train_neg[i])\n",
    "    train_neg_nb.append(temp)\n",
    "    \n",
    "test_pos_nb = []\n",
    "for i in range(len(test_pos)):\n",
    "    temp = \" \".join(test_pos[i])\n",
    "    test_pos_nb.append(temp)\n",
    "    \n",
    "test_neg_nb = []\n",
    "for i in range(len(test_neg)):\n",
    "    temp = \" \".join(test_neg[i])\n",
    "    test_neg_nb.append(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T19:23:48.419128Z",
     "start_time": "2019-12-21T19:23:48.411600Z"
    }
   },
   "outputs": [],
   "source": [
    "x_train = train_pos_nb + train_neg_nb\n",
    "y_train = [1]*12500 + [0]*12500\n",
    "x_test = test_pos_nb + test_neg_nb\n",
    "y_test = [1]*12500 + [0]*12500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T19:23:52.821018Z",
     "start_time": "2019-12-21T19:23:52.008505Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.str_"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xt = np.asarray(x_train)\n",
    "type(xt[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T19:24:04.044221Z",
     "start_time": "2019-12-21T19:23:56.599089Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000, 10000) (25000, 10000)\n"
     ]
    }
   ],
   "source": [
    "vectorizer = TfidfVectorizer(max_features=10000)\n",
    "train_vectors = vectorizer.fit_transform(x_train)\n",
    "test_vectors = vectorizer.transform(x_test)\n",
    "print(train_vectors.shape, test_vectors.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T19:24:07.783195Z",
     "start_time": "2019-12-21T19:24:07.735348Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.83472\n"
     ]
    }
   ],
   "source": [
    "clf = MultinomialNB().fit(train_vectors, y_train)\n",
    "predicted = clf.predict(test_vectors)\n",
    "print(accuracy_score(y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compare results for dictionary vs. NB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-12-21T19:24:23.214760Z",
     "start_time": "2019-12-21T19:24:23.135604Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary Method:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.69      0.74      0.72     12500\n",
      "           1       0.72      0.67      0.70     12500\n",
      "\n",
      "    accuracy                           0.71     25000\n",
      "   macro avg       0.71      0.71      0.71     25000\n",
      "weighted avg       0.71      0.71      0.71     25000\n",
      "\n",
      "Naive Bayes:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.87      0.84     12500\n",
      "           1       0.86      0.80      0.83     12500\n",
      "\n",
      "    accuracy                           0.83     25000\n",
      "   macro avg       0.84      0.83      0.83     25000\n",
      "weighted avg       0.84      0.83      0.83     25000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Dictionary Method:')\n",
    "print(classification_report(True_label,Bing_analysis))\n",
    "print('Naive Bayes:')\n",
    "print(classification_report(y_test,predicted))"
   ]
  }
 ],
 "metadata": {
  "gist": {
   "data": {
    "description": "CSS/10.1.ipynb",
    "public": true
   },
   "id": ""
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "310px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
